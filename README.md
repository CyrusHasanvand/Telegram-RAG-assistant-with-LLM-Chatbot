# Telegram RAG assistant by LLM chatbot and MySQL
*A local LLM-powered chatbot with Telegram integration and MySQL-based conversation logging.*

Assume that you have a product and want to hire an AI to communicate with users through Telegram on behalf of your team as an employee, in which an AI agent responds to users automatically based on the retrieved information or by mixing information of both the AI's pre-knowledge itself and your data. Therefore, having an intelligent AI would be the most important thing to provide for your customers. They can communicate with your AI agent to learn more about your company's aim, products, and related information from AI suggestions to let users engage beneficially with your team and items. More importantly, this communication is available everywhere and at any time of the day. Accordingly, I consider this challenge and, by using ```MySQL``` to save the data, I develop an AI-based Chatbot that could increase user satisfaction by experiencing a new evaluation of options at a company.

## Why Telegram?
In this project, I have utilized Telegram for this command because of its capabilities, diversity, and security. You can use an alternative based on what you prefer. However, you only need a chat environment, which could be designed on your own website.

## Framework setups
To develop this project, we need to handle three main subjects, including ```i)``` Chatting environment (which is Telegram here); ```ii)``` LLM model in the backend (which is local ```llama3.1``` in this project); and ```iii)``` a database to save the logs and chats (which is ```MySQL``` in the current mission).

### i) Creating Telegram chatbot
We need an API to connect our chats with the backend structures. Therefore, we have to address a ```token``` number in Telegram to connect the chats with our backend LLM model through an ```HTTP API```.

Assume that we have a token to access the HTTP API as follows:
```
1023456789:AWFETzeOSSkGyskv1anq5QvTKibQsz-G5xi
```
(Attention: This token is an example and not generated by Telegram)
### ii) Local LLM model
You can select your local LLM model among the many available language models, such as OpenAI's GPT models, HuggingFace models, or Local LLM models. In this project, I have employed ```Ollama (llama3.1)``` model to handle the backend. Even though ```llama3.1``` is built on ```7B``` parameters, it can generate a very accurate response, which I highly recommend for users with limited storage and graphics card. It can also run on a CPU.

### iii) MySQL in practice for database management
In this project, I have utilized MySQL to save the chats. Having this in mind, before any process with the codes, I needed to create a database as follows:
<a name="MySQLCode"></a>
```SQL
create database ChatBotDB2;
use ChatBotDB2;

create table logs (
	id INT auto_increment primary KEY,
    user_id bigint,
    username varchar(100),
    message text,
    reply text,
    create_at Timestamp default current_timestamp
);
```
where I saved the main important ```logs``` for this project as ```User-ID```, ```Username```, ```User's Message```, and ```AI response```.
This file is uploaded as ```ChatBotDB2.sql```.

## Intelligent Chatbot
Please consider the following question of a user and the AI's response to the request:
<a name="fig-Mess1"></a>
![Figure 1](Images/Im_01.png)

*Figure 1: The first message of the user.*

As you can see in [Message 1](#fig-Mess1), the user asked us how a person can learn ```Tensorflow```, and ```llama3.1``` provided a concise response to the request.

It's worth noting that I designed a general purpose for this project. Assume that you have a product, then you can design your own fine-tuned LLM model for your customized product. I mean, you can consider a shop with several products, then you can manage your intelligent model to respond and suggest items to your customers.

Look at the following suggestion from ```llama3.1``` for another user's question:

<a name="fig-Mess2"></a>
![Figure 2](Images/Im_02.png)

*Figure 2: The second message of the user.*

[Message 2](#fig-Mess2) indicates how the model can provide a meaningful response to the user's request.

## Prompt
In this project, I used a prompt with the following considerations:
```python
system_prompt = """
You are an expert AI assistant.
Answer concisely but fully.
Limit each response to 100 words if possible.
"""
```
This ```prompt``` would be changed to reflect our desire. Prompt is one the crucial parts of a training LLM model.

## Retrieval Information and Chat Analysis
I have employed [MySQL](#MySQLCode) in this project to save the chats.
This is very important for future analysis of the previous communications regarding both the performance of the model and knowledge interaction with users.
Consider the following chat between the AI-based chatbot with previous users when the user wanted to translate previous information into the English language.
![](Images/Im_03.png)

You can see that the model can retrieve information to address the user's question. The following chat also consolidates this retrieved knowledge, where the intelligent model could accurately respond to the question. 
![](Images/Im_04.png)

## Application
Now, assume that you have your shop market and are pleased to manage your products with your customers in a way that enhances the delivery of the most relevant items to your customers to increase both productivity and customer satisfaction.
Furthermore, customer experience could also be analyzed by a separate LLM model such as [LangChain PDF-to-LLM Q-A with RAG](https://github.com/CyrusHasanvand/LangChain-PDF-to-LLM-Q-A-with-RAG) or [Context-Aware LLM Chatbot](https://github.com/CyrusHasanvand/Content-aware-chatbot-with-LLM-) to check them ```sentiments``` or ```summarization``` for further evaluations.









